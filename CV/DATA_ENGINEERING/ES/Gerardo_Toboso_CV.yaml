# yaml-language-server: $schema=https://raw.githubusercontent.com/rendercv/rendercv/refs/tags/v2.5/schema.json
cv:
    name: Gerardo Toboso
    headline: Ingeniero de Datos
    location: Buenos Aires, Argentina
    email: gerardotoboso1909@gmail.com
    phone: (+54) 911-4045-6207
    social_networks:
        - network: LinkedIn
          username: gerardo-toboso-512a48290
        - network: GitHub
          username: Gerardo1909

    sections:
        resumen:
            - Data Engineer especializado en el diseño de pipelines cloud-native sobre AWS, con enfoque en arquitecturas serverless, idempotencia y validación temprana de datos. Experiencia construyendo Data Lakes en Amazon S3, pipelines event-driven con AWS Lambda y almacenamiento particionado en Parquet optimizado para analítica. Fuerte orientación a calidad de datos, observabilidad (CloudWatch) y diseño costo-eficiente en entornos productivos.

        habilidades:
            - label: Arquitectura de Datos & Diseño Cloud
              details: Arquitecturas event-driven en AWS, Data Lakes en Amazon S3, diseño de pipelines idempotentes, particionamiento Hive-style (Parquet), modelado dimensional (Star Schema, SCD Type 2), Data Contracts y políticas de frescura (SLA de datos)
            - label: Ingeniería de Datos & Procesamiento
              details: Python (pandas, PySpark, duckdb), desarrollo de ETL/ELT, procesamiento distribuido, diseño de DAGs y monitoreo en Apache Airflow, datasets versionados y segregación de datos válidos/rechazados
            - label: Bases de Datos & SQL
              details: SQL avanzado para analítica, PostgreSQL, optimización de queries e indexación, análisis de execution plans, tablas particionadas y modelado para cargas analíticas
            - label: Cloud & DevOps (AWS)
              details: AWS Lambda, Amazon S3, IAM (principio de mínimo privilegio), CloudWatch (logs y monitoreo), EventBridge, ECR (containerización), Docker y CI/CD con GitHub Actions
            - label: Calidad de Datos & Observabilidad
              details: Validaciones basadas en reglas de negocio, testing automatizado con Pytest, logging estructurado, detección de fallos y segregación de registros inválidos para auditoría
            - label: Idiomas
              details: Español (Nativo) | Inglés (Fluido - C2)

        experiencia:
            - company: Hotel Serverless Pipeline – AWS Data Architecture (Proyecto Personal)
              position: Ingeniero de Datos
              location: "[GitHub](https://github.com/Gerardo1909/hotel-serverless-pipeline)"
              start_date: 2026-01
              end_date: 2026-02
              highlights:
                  - Diseñé e implementé un pipeline de datos completamente serverless en AWS (S3 + Lambda + EventBridge).
                  - Automatizé la detección de nuevos lotes en S3 y la ejecución de transformaciones mediante triggers event-driven.
                  - Consolidé múltiples CSV en datasets particionados en Parquet (Hive-style) optimizados para Athena.
                  - Implementé reglas de validación (precio, fechas, rangos de score) con segregación automática de datos rechazados.
                  - Diseñé el sistema bajo principios de idempotencia (reintentos seguros, sin duplicación).
                  - Configuré IAM con políticas de mínimo privilegio y monitoreo centralizado en CloudWatch.

            - company: ETL para datos IoT (Proyecto Personal)
              position: Ingeniero de Datos
              location: "[GitHub](https://github.com/Gerardo1909/iot-etl-pipeline)"
              start_date: 2025-12
              end_date: 2026-01
              highlights:
                  - Diseñé arquitectura tipo Medallion (Bronze → Silver → Gold) procesando millones de eventos IoT diarios.
                  - Implementé transformaciones distribuidas en PySpark alcanzando ~50GB/min sin cuellos de memoria.
                  - Arquitecté un Data Lake en Amazon S3 con particionamiento y versionado para soportar >1TB/día.
                  - Definí controles de calidad y alertas de fallos logrando 99.9% de disponibilidad del pipeline.
                  - Modelé capa analítica dimensional (Star Schema) lista para consumo BI.

        educación:
            - institution: Universidad Nacional de San Martín (UNSAM)
              area: Ciencia de Datos
              degree: Licenciatura
              location: Buenos Aires, Argentina
              start_date: 2022-07
              end_date: present
              highlights:
                  - "75% completado — Promedio: 9.0 / 10"

design:
    theme: engineeringresumes
    page:
        size: us-letter
        top_margin: 0.5in
        bottom_margin: 0.5in
        left_margin: 0.5in
        right_margin: 0.5in
        show_footer: false
        show_top_note: false
    templates:
        education_entry:
            main_column: "**INSTITUTION**, DEGREE en AREA\nSUMMARY\nHIGHLIGHTS"
            degree_column:

settings:
    render_command:
        dont_generate_markdown: true
        dont_generate_html: true
        dont_generate_png: true

locale:
    language: spanish
    present: presente
